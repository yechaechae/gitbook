## 효과적인 국제학술지 투고 전략1 오광일 이사


논문을 투고하기 전 일반적인 과정 전에 알아야 할 것 

-> 리뷰어들(에디터, 피어 리뷰어)이 어떤 성향인지 알아야 한다.
관심 없으면 성의없이 넘어가는 사람도 많다.

* 저널 에디터 
저널의 명성, 임팩트 팩터 향상에 도움될지 ?
요즘은 코로나 관련 주제가 좋다.

* 저널 편집자의 관심사 
편집자가 보는 첫번째 항목 - 요즘은 초록 보다 cover letter를 많이 본다. 

에디터와 연락 해도 된다.

* 에디터가 논문을 읽는 순서 
figure table도 중요하다.

* 키워드 
검색을 위해
키워드가 초록 안에만 존재하면 안되고 본문에 필요한 곳에 곳곳에 있어야한다. 

* 표절 
인용, 문장을 잘 바꿔서 쓰기

* 저널 에디터의 업무프로세스 : 표절이 의심되는경우
1. 저자한테 물어보고 수정
2. 저자의 답변 X , 불성실 -> 소속기관에 통보

* 논문을 작성할 때 출처를 밝혀
* 합성한 이미지는 figure legend에 설명해야 한다.
* 저자됨(suthorship) 논쟁
    * 4가지 잘 확인 해 봐.

* 커버레터와 초록의 차이점
    - 초록은 논문에 관한 내용만
    - 커버레터는 연구 전반적인 내용(제목, 저자 소개, 이유, 요약, 모든 저자들이 동의했다는 동의 등) -> 한 페이지 내
    - 에러 단순요약, 일반적인 정보만 수록 tip : ppt
    - 커버레터에서 어필을 많이 해야한다. 정부지원 -> 반드시 명시 
* 논문 작성하기 전 계획을 해라 
* 많은 에디터들 말
    - 가장 많이 reject 당하는 경우 : 학술지와 맞지 않은 논문, 가이드라인 맞지 않은 논문, reject 했는데 수정하지 않고 다시 낸 경우(A저널,B저널 리뷰어가 같은 경우)
* 투고저널 선택기준
* 투고 성공률을 높일 수 있는 저널 선택 (출판 웹 참고)

* 리뷰 의견 분석 결과 
* 피어 리뷰 과정은 논문을 더 좋게 만들어 주는 과정이다.

** 가이드라인이 중요하다. **

* response letter를 쓸 때
p.70 

* Open Access
장점 : 독자층이 넓어진다. 
단점 : 저자 비용 증가

* Journal Predatory
JCR에 등재가 되어야 Impact Factor가 있다고 얘기할 수 있다.

p. 104 : 모든 저널 검색 가능 웹


## Structure of a scientific manuscript 오광일 이사

* 제목 : 짧고 간결하고 매력적이게
    - 동사 : 능동형, 현재시제
    - 단어 수도 가이드라인에 정해져 있음
    - 약어나 jargon은 쓰지 않는다. 
    - 키워들 리스트업
    - 필요하면 부타이틀도
1. what is my paper about ?
    predict
2. what techniques/designs did i use?
    machine learning
3. who/what did i study?

4. what were the results?  
    - 논문 제목은 논문을 다 쓴 후 작성 
why ? 학회별로 논문 제목이 다르게 바뀔 수 있기 때문에 

* 초록 
    - 연구의 결과를 포함 해야한다.
    - 비전문가도 읽을 수 있을 정도의 초록
    - 초록 구조는 가이드라인 보고 확인
    - p.57 색깔별로 intro, method, result, discussion, coclusion
    - 논문 다 쓰고 마지막에 쓰는 것 

* 서론 
    - background + question 
    - 연구의 목적 1문장 간략하게 
    - 선행연구를 바탕으로 왜 이런 연구를 하는지?

* 실험 방법 experiment
    - 동물 관련한 실험이면 학교의 IRV에 가야함 IRV가 뭐야 ..?
    - 재료, 대상 어떤 프로그램? 잘 명시, 어떤 결과? 정리


* result 
    -> method의 결과, 데이터 위주 
    - 논리적인 순서가 있어야한다.
    - 숫자보단 %정보 

* discussion 
-   데이터를 바탕으로 어떤 의미가 있는지 분석

* answer + Implication 
    - 질문의 답 

* writing tips p.59
* signal topics 
    - 논문 읽으며 괜찮은 문장구조를 저장

*** 가이드라인!! ***

IMRaD 구조

    - 연구의 한계성 꼭 적기
* Discussion 
    - 새로운 거 X

* method
    - 관련 연구도 필요하다면 method 앞 부분에서 간략하게 정리 가능


## Common Mistakes by Korean Authors
    - 스타일 or 퀄리티가 일관성이 없는 경우
    - 영국, 미국 영어가 섞여 있는 경우(spelling)
    - 문장 연결이 매끄럽지 않은 경우

* 초록
    - 초록에는 레퍼런스 달지 말것 

* 관사
    - A/An : 셀 수 있는 명사 앞에 
    - The p.21
    - hyphen, en dash ~ 물결표시는 정확한 수치가 아니라서 물결표시를 쓰지 않는다., em dash

* Abbreviations (약어)
    - 본문에 자주 나오면 처음에만 풀어쓰고 다음부터는 약어, 한번반 나오면 풀어서 쓰기
    - :, ;는 리스트 

* 자주하는 문법 실수 p.36 ~ 

* p.53 책임이나 행위가 불분명 해질 수 있으니 수동태 보다는 능동태 



## How to prepare Your Papers in Premier Conferences

좋은 연구를 하는 전반적인 process
* 왜 프리미어 컨퍼런스가 중요한가 ?
* 추천 시스템 간단한 소개

* 프리미어 컨퍼런스
    - 기술의 사이클이 짧기 때문에 컨퍼런스가 존중 받고 있다.
    - 프리미어 컨퍼런스에 논문이 게재되면 그 분야에서 R&D를 할 수 있는 능력이 있다고 인정 해 준다.
    - 요새는 회사에서도 인정 해 준다.(Google, Samsung, etc..)

why? 
- R&D에 있어서 all-round player라고 여겨진다.

* 탑티어 컨퍼런스 논문을 준비하려면 무엇을 조심해야하는가??
추천 시스템 분야로 예를 들겠다!

* 탑티어의 논문은 어떻게 준비하는가?
* Survey(research)가 매우 중요하다!
    - 토픽이 결정 되면 중요한 논문을 찾는것이 중요!
        - 잘못된 논문을 보면 잘못된 방향으로 갈 수 있다.
        - 구글스칼라 or MS academic
    - 좋은 논문은 좋은 논문을 인용한다. 
    - 약 20~30개의 논문을 읽어봐라

* 논문 제대로 읽기
    - 논문에서 해결하려고 하는 문제?
    - 문제를 해결 할 수 있었던 key idea?
    - 기존의 것과 key idea를 비교
    - 논문을 읽으면서 어떤 문제를 해결할지 생각
    - 왜 top-level conference에 게재 됐는지 이해
    - 스스로 설명할 수 있도록 (5분, 10부느 20분)
    - 20~30편의 페이퍼를 읽어보면 그 분야의 전체적인 그림을 그려본다.
    - 로드맵이 그려지도록 (어떻게 이 idea가 시작되었고 이 idea의 어떤 문제를 풀기 위해서 이런 idea가 나왔고,,,)
    - 그리다 보면 기존 연구의 문제가 자연스럽게 떠오른다.

* Solving a Problem
    - 기존의 솔루션을 개선하는 형태
        - 정확성 
        - 빠름
        - Scalable
        - Incremental ex) 기존에는 새로 들어온 데이터를 기존 데이터와 합쳐서 다시 새로 해야하는데 나는 새로 들어온 데이터를 다시 합치지 않고 해결 ! 
        - Explainable 왜 딥러닝 모델이 이런 예측을 했는지 설명 가능
        - Parameter-free / parameger-insensitive
    - Requirements
        - 직관, 왜 좋아졌나?
        - Novel
        - Effective
        - Simple - 예) 개념이 너무 심플해서 리젝 당했지만 다시 해서 보냈는데 리뷰어왈 개념이 너무 간단하지만 정확도를 너무 잘 높였고  개념의 중요성에 대한 실험을 잘 했기 때문에 억셉했다.
    - 인접분야
* Implementation
    - 올바르게
    - 올바르지 않은 코드로 실험해서 결과가 잘못 나올 수 있다.
    - 신뢰성 있는 코드 확인하는법
        - 기존의 논문의 결과와 비교 
        - 똑같은 문제를 참조하지 않고 두명이서 코딩해보고 같으면 OK
        - 오픈소스 활용(탑티어 논문 저자)
* Evaluation
    - 우리의 아이디어가 기존의 아이디어보다 좋다는 것을 보여줘야한다.
        - 우리의 결과가 최신의 방법보다 정확한가?
        - parameter X
        - 
    - 웬만하면 실험의 세팅이 같아야한다.
        - 데이터셋, 메트릭, 경쟁자
        - 정말로 바꿔야하면 정확히 왜 바꿔야 했는지 적어라
        -> contribution 될 수 있다.
* Evaluation
    - 더 많은 데이터셋, 메트릭, 경쟁자 (정성을 보이자) 
    - Reproducivility
        - 코드와 데이터셋을 공유
        - 파라미터 세팅을 명확하게 명시
    - 통계 어쩌고

* writing a paper
    - 추리소설 쓰는 것과 완전 반대방향으로 가면 된다.
    - 둘의 차이
        - 추리소설 : suspense가 목적 
        - 논문 : 
            - 명확하게
            - 시작부터 결과를 명확하게
            - 예측 가능하게 쓰기
    
    - 구조
        - Abstact : 아이템의 중요점을 강조
            - 문제? 
            - 해결방법?
            - 왜 중요?
        - Introduction : 
            - 제목, abstract, introduction : anchor
            - 논문이 accept되는데 아주 중요하다.
            - 논문의 1/3, writing 실력과 좋은 아이디어일지 판단 가능
            - 괜찮아 보이면 나머지 2/3을 더 읽는다.
            - 구조
                - 문제 기술, 왜 이 묹를 풀어야하는지
                - background, 이전 work
                    - 최신기술 요약, ..
                - 결과
                    - 내 공헌을 잘 강조
                - 논문의 구조 설명
        - Conclusions
            - Introduction과 달라야한다.
                - Assumption : 이미 논문을 읽었다고 가정
                - 앞서 나왔던 단어, 문제를 discuss
            - Structure
                - 공헌을 한번 더 강조해서 정리
                - 이후에 추가적으로 연구 할 것이다.

시키는 일만 하지말고 indendent한 연구자가 되어라! 
    - 왜 이런식으로 일을 시키는지 생각해보고
    - 왜 이렇게 시키는지 이해가 안가면 이해가고 넘어가라
    - 생각하고 이해하고 넘어가라


예시
Told you i didn't like it: Exploiting Uninterestign Items for ~~

Motivation
    - 기존에는 사용자들이 준 review 점수로 추천시스템
    - 보통 density가 낮다. 데이터가 sparse하게 분포 되어 있어서 정확도가 낮다.(data sparsity problem)
Formulating a Problem
    - data sparsity problem을 해결해서 추천의 정확도를 높이는 것이 우리의 research problem이다, 
    - Source: other papers
    - Falsifiable
        - by validating the final recommendation accuracy 풀기전의 정확도와 비교 가능
    - Important
        - 추천의 정확도를 높이면 매출이 엄청난 차이를 보이기 때문에 매우 중요하다.
    - Timely
        - 10년 전부터 논의 된 문제라서 엄청 hot 한 문제는 아니지만 아직 중요하다.
    - Having real-world data and ground truth
        - 많은 데이터셋이 존재한다. 
-> 문제가 되기에 적당하다고 말 할 수 ㅣㅇㅆ다.

Our Idea for Solving the Problem
    - 기존에는 존재하는 점수로 문제를 풀려 했다.
    - 존재하는 점수의 비율 = density 
    - density가 보통 4%, 실제 데이터에서는 0.04% 정도 된다.
    - 기존의 문제점: 4%는 중요한 데이터로 여기면서 나머지 96%의 데이터를 과감하게 버리고 시작한다는 점을 문제로 생각 했다.
    - 96%에 있는 unrated 아이템을 잘 활용해보자. 
    - unrated item
        - 사용자가 존재하는지도 몰랐다. -> 추천 후보
        - 존재하는지 알지만 싫어하는 아이템 -> uninterestign items
        -> 두 가지의 데이터가 unrated item에 혼재 되어 있다.
    - unintersting 아이템을 찾아서 이용하자. -> main idea

    - unrated item 중에서 uninteresting 할 정도를 machine learning으로 계산.
    - 낮을 수록 관심 없음 관심이 없을 것 같은 것을 찾아서 0점을 준다.
    - 위의 matrix를 이용하니 정확도가 올라나다.
    - 중요한점 : 기존의 matrix를 계속 사용할 수 있다. ex) 추천시스템 정확도를 높이고 싶은데 기존의 시스템을 갈아엎어야한다. or 기존의 시스템을 그대로 두고 내 모듈만 넣음녀 된다.
    - 리뷰어나 리더가 궁금해할 만한 질문을 뽑고 
    - 그 질문을 해소하는 방향으로 실험을 디자인 함.
    - 심사위원 의심 : 기존의 matrix에 0점을 추가적으로 집어넣었다. 데이터가 추가 되었는데, 너의 방법은 시간이 더 많이 걸리는 나쁜점이 생긴것이 아닌가? 
    - 아니다, 우리는 정확도도 높고 더 빠르다라고 주장하면 안된다. -> 시간이 4배 정도 더 걸리지만 정확도가 높아진다.
    - reject 당함 -> 아이디어는 참신하지만 novelty 하지 않다 -> 기존의 아이디어를 많이 사용함
    - 이후 논문에서 우리의 메인 아이디어는 테크닉을 제안한 것이 아닌 uninteresting 이라는 개념에 대해서 설명한 것이다. 우리 방법의 의미를 좀 더 살림.
    - 검증 방법 다양하게 
    - 데이터셋 적다고 불만
    - 정말로 uniteresting 인지 아닌지 모르지 않나? 다른 이유가 있을 수도 있는거 아닌가? -> 시키는대로 실험
    - 시간 많이 걸리는거 왜 솔직하게 보여주지 않았나? 
    - 내 연구를 전문가의 눈에 의해서 정말로 적잘한것인가? 충족시켜야한다.


전체적인 매트릭스안에 셀들 중에 점수들이 들어있는 수를 density라고 하는데 이가 매우 낮다 -> 사용자들의 취향이 드러나 있지 않다. -> Data sparsity problem

추천의 정확도를 높여 data sparsity problem을 해결하는 것,
source를 읽으면서 data sparsity problem이 문제인 것을 알았다.






