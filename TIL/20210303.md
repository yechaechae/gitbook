## 군집화 (clustering)
- 비지도학습
- 클러스터란 비슷한 특성을 가진 데이터들의 집단
- 예측을 하는데 사용하기 보다는 데이터에서 의미를 파악하고 기준을 만드는데 사용
- 아무런 정보가 없는 상태에서 데이터를 분류하는 방법
- 데이터 클러스터링 ? 여러번의 반복을 통해 데이터의 최적 분할을 진행하는 방법
- 이중 가장 유명하고 간단한 K-menas Clustering

2. 군집화 알고리즘
(1) K-means 알고리즘
* 군집 중심점이라는 특정한 임의의 지점을 선택해 해당 중심에 가장 가까운 포인트들을 선택하는 군집화 기법
* 선택된 포인트의 평균지점으로 이동하고 이동된 중심점에서 다시 가까운 포인트를 선택, 다시 중심점을 평균 지점으로 이동하는 프로세스를 반복적으로 수행
* 장단점 명확 튜닝 필요

|  장점  |      단점      | 
|----------|:-------------:|
| 일반적으로 군집화에서 가장 많이 사용되는 알고리즘, 알고리즘이 쉽고 간결 |   거리기반 알고리즘으로 속성의 개수가 매우 많을수록 군집화 정확도가 떨어짐, 반복을 수행하는데 반복횟수가 많을 경우 수행시간이 매우 느려짐 |

(2)K-means++ 알고리즘
(3)ISODATA 알고리즘
(4) 평균이동  
....
참고[https://rosypark.tistory.com/110]


## 분류(Classcification)
- 지도학습의 일종
- 기존에 존재한느 데이터의 Category 관계를 파악하고, 새롭게 관측된 데이터의 Category를 스스로 판별하는 과정이다.

1. 알고리즘 종류
(1) KNN
- K개의 가장 가까운 포인트 선점, 그 중 가장 많이 선택된 포인트의 카테고리로 이 새로운 데이터를 분류하는 방법
(2) Decision Tree 의사결정 트리
- yes or no
(3) Random Forest
- Decision tree가 여러개 모여 Forest를 이룬 것
(4)Naive Bayes(나이브베이즈)
- 확률 사용
(5)SVM(Support Vector Machine)
- 기본적으로 Decision Boundary라는 직선이 주어진 상태
- Decision Boundary로 결과 예측

출처 : https://bangu4.tistory.com/99

## 회귀분석(Regression)
참고 : https://wikidocs.net/21670


## 정규화 
-  데이터가 가진 feature의 스케일이 심하게 차이가 나는 경우 문제
참고 : http://hleecaster.com/ml-normalization-concept/


## outlier 
data pre processing 과정에서 outlier removal을 진행 
outlier란?
데이터들 중 유독 차이가 많이 나는 데이터 값? 이는 실수 일수도 있고 다양한 데이터 중에 하나일 수도 있다. 이 데이터가 중요한지 아닌지 어떻게 결정할건데?
간단, 실수면 무시하고 아니면 좀 더 생각해봐야한대


## R
* <<- 연산자 : 전역변수로 선언

# CLUTCH: A Clustering-Driven Runtime Estimation Scheme for Scientific Simulations

https://www.notion.so/yechae/CLUTCH-A-Clustering-Driven-Runtime-Estimation-Scheme-for-Scientific-Simulations-c7cfea4eeee742899857bd585d476d76#543e7ce3350f43868bc8b640fab64525

## Abstact

시뮬레이션 제한된 I/O 리소스. 긴 시간의 기다림 등의 문제를 해결하기 위해서 시뮬레이션 런타임 측정 스킴 "CLUTCH"를 제안, clustering, classification, regression 기법의 앙상블 을 사용해서 

제안된 스킴은 런타임 측정모델을 몇 가지의 스텝으로 나눠 훈련 시켰다.

1. 과거의 시뮬레이션 기록들을 클러스터링으로 그룹핑
2. 각 그룹화된 기록들을 classification으로 라벨링
3. 각 그룹의 실행시간에 regression 적용 (?)

측정 품질을 높이고 트레이닝 오버헤드를 줄이기 위해서 두 가지의 optimization 알고리즘을 제안 

이 실험에서 약 14.2%의 측정 정확도를 높였다.  우리 모델은 16배 빨리 훈련 시켰다.

## 서론

CLUTCH 스킴은 런타임 측정 성능에 가장 영향을 주는 두가지의 주요 이슈를 다룬다.

1. data pre-processing 

data pre-preocessing을 하는 과정에서 PCA를 적용하지 않는 방향이 simulation data를 예측하는데 더 좋은 영향?을 보여줌 
k-means optimizing했는데 8%의 차이?

- 새로운 런타임 측정 스킴이 제안되었다. clustering, regression and classification 기술의 ensemble.
- 두가지의 optimization 방법이 이 스킴에 사용되었다. 
    - 최고의 pre-processing permutation을 찬기위해서
    - cluster의 optimal number를 알아내기 위해서 
- 논문에서 제안된 모델은 온라인 시뮬레이션 측정 플랫폼의 실제 데이터를 사용해서 성능을 측정했다.
- 제안된 스킴은 약 14%의 정확도를 획득 
## related work 
다른 연구들과 이 연구가 무엇이 다른지 서술

?? 서론에서 data pre-processing 할 때 PCA 없이 예측하는게 더 좋은 영향을 준다고 본 것 같은데 왜 figure2에서 preprocessing phase 단게에서 PCA가 들어간것인지..?