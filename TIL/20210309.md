일단 머신러닝, 데이터 분석에 대해서 거의 아는게 없고 어떤 식으로 공부해야할지 방향을 잘 모르겠다.
그래서 대표 예제들을 살펴보고 다른 사람들은 어떤식으로 풀었는지 다방면으로 살펴보며 어떤 식으로 공부해 나가야하고 
어떤 식으로 데이터를 분석 할것인지 알아보자.

[2020년 해 볼만한 인공지능 및 머신러닝 프로젝트 20선](https://insightcampus.co.kr/insightcommunity/?mod=document&uid=12887)

### Classifying Iris Flowers 
[EX 1](http://rstudio-pubs-static.s3.amazonaws.com/420656_c17c8444d32548eba6f894bcbdffcaab.html)
1. 데이터를 summary 해 보니 빈 데이터는 없기 때문에 따로 데이터 전처리를 할 필요는 없다.
2. 분석
    * chain operation에 대해서 알 수 있었다.  [chain operation](https://rfriend.tistory.com/236)
    * box plot 그래프로 setosa의 petal length와 width가 다른 두 종류의 것들 보다 현저히 적다는 것을 알았다.
    * 각 종의 데이터들로 [선형관계가(linear relationship)](https://m.blog.naver.com/PostView.nhn?blogId=yunjh7024&logNo=220819925829&proxyReferer=https:%2F%2Fwww.google.com%2F) 있는지 확인 해 보니 sepal measurements로는 Versicolor과 Virginica의 종을 구분하기 힘들었지만 petal measurements에서는 구분할 수 있었다. 
3. 모델 트레이닝
    a. Discriminant Analysis (판별분석)   [분류(로지스틱, LDA, QDA) 이해하기](https://godongyoung.github.io/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2018/01/23/ISL-Classification_ch4.html)
    * 예측변수가 2 개보다 많은 문제에서는 LDA 알고리즘을 쓰는 것이 좋다. 
        * lda 알고리즘을 사용한 결과를 보니 LD1의 데이터가 종을 구분하는데 더 많은 기여를 한 것이 보인다.(99%)
    * LDA 모델이 Iris 종을 예측하는데 좋은 모델인지 확인 (모델 성능 평가)
        * confusionMatrix함수를 사용하여 정확도 평가 -> 약 96% 로 확인 된다.
    b. Decision Tree(결정 트리) [참고](https://godongyoung.github.io/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2018/02/23/ISL-Tree-Based-Methods_ch8.html)
    * 예측 변수가 적을 때 출력은 일반적으로 쉽게 해설 할 수 있고 non-parametric이므로 혼합 된 변수 유형을 처리하는 데 능숙하다.
        * 이 모델이 두 개의 꽃받침 변수를(sepal.width, sepal.length) 수용하지 않는다는 점이 흥미롭다 
    * 정확도 : 3개의 꽃을 잘못 분류해서 3/30 = 90%의 정확도를 보여준다.
    * 그러므로 LDA 모델 보다 좋지 않다고 볼 수 있다.
    c. Random forests   
    * regression 모델과 달리 모델을 fit 하기 전에 hyperparrameters를 선택 해야한다. 그러나 일단 돌려 보고 조정 하려나보다.
    * 이 모델의 Out-of-bag오류는 3.33%로 96.7%의 정확도를 제공
    * petal의 데이터가 더 중요한 것으로 보여진다. 이전과 같다.
    * 정확도 별로
    d. K-nearest Neighbour
    * k를 1-10 으로 해서 10개의 모델을 만든다.
    * k 가 3보다 클때 부터 모델의 정확도가 조금 향상 했다. 그러나 높아 봤자 93.9%이다. 
    
4. 결과 
    * LDA가 가장적합, 그다음 KNN 
    * 모든 트리 기반 알고리즘은 최악의 결과를 보여준다. 광범위한 데이터세트가 없었기 때문에..? 
    * LDA는 4개의 변수를 모두포함 하므로 데이터 내의 분산을 보다 정확하게 반영 할 수 있었다.
    * 4개의 변수 중 2개를 제외하거나 무시한 트리 알고리즘은 정확도가 낮았다.

    [참고 1](https://www.neuraldesigner.com/learning/examples/iris-flowers-classification)
    [참고 2](https://github.com/trevorwitter/Iris-classification-R)
    [참고 3](https://rpubs.com/ryoo/iris_ml)


    [Causal Interference](https://www.slideshare.net/lumiamitie/causal-inference-primer-20190601)